---
layout: post
title:  "3. Строки"
date:   2015-09-18 21:27:00
categories: go
---

В этой главе рассматриваются тип string и основные пакеты из стандартной библиотеки для работы со строками. В отдельных разделах
главы рассказывается, как записываются строковые литералы и как
используются строковые операторы, как индексировать строки и извлекать срезы (подстроки) из строк и как форматировать вывод строк,
чисел и других значений, встроенных и пользовательских типов.
Высокоуровневые средства языка Go для работы со строками,
такие как цикл for ...range, позволяющий выполнять итерации
по символам строк, функции из пакетов strings и strconv и возможность извлечения срезов строк, включают все необходимое для
решения повседневных задач. Тем не менее в этой главе подробно
рассматриваются особенности строк в языке Go, включая низкоуровневые, такие как внутреннее представление строк. Низкоуровневые аспекты строк представляют определенный интерес, и их знание
может пригодиться в некоторых ситуациях.

Строки в языке Go являются неизменяемыми последовательностями произвольных байтов. В большинстве случаев байты в строках
представляют текст Юникода в кодировке UTF-8 (см. врезку «Юникод» выше). Наличие поддержки Юникода означает, что строки в
языке Go могут содержать текст на смеси любых языков, известных
в мире, без ограничений, накладываемых кодовыми страницами.

Тип string в языке Go в корне отличается от эквивалентных
типов во многих других языках. Тип String в языке Java, std::string
в языке C++ и str – в Python 3 – все они являются последовательностями символов фиксированного размера (с некоторыми ограничениями), тогда как строки в языке Go являются последовательностями символов переменного размера , где каждый символ может быть
представлен одним или более байтами, обычно в кодировке UTF-8.

На первый взгляд может показаться, что строки в других языках
удобнее, чем строки в языке Go, потому что они позволяют обращаться к символам непосредственно, что в языке Go возможно, только
если строка состоит исключительно из 7-битных символов ASCII (так
как в кодировке UTF-8 каждый из них представлен единственным
байтом). Однако с практической точки зрения подобное отличие не
является проблемой для программистов на языке Go: во-первых, потому что прямое обращение к символам нечасто бывает необходимо
благодаря поддержке итераций по символам строк; во-вторых, потому
что стандартная библиотека содержит исчерпывающий набор функций для работы со строками; и в-третьих, потому что в языке Go
строки всегда можно преобразовать в срезы с кодовыми пунктами
Юникода (типа []rune) и обращаться к ним непосредственно.

Хранение текста в кодировке UTF-8 имеет определенные преимущества, по сравнению, скажем, со строками в языке Java или
Python, каждый из которых также поддерживает строки Юникода.
В языке Java строки представлены последовательностями кодовых
пунктов, каждый из которых занимает 16 бит; в Python, в версиях
с 2.x по 3.2, используется тот же подход, но в нем для хранения
кодовых пунктов отводятся 16 или 32 бита, в зависимости от параметров сборки Python. Это означает, что для текста на английском
языке в Go отводится по 8 бит на каждый символ, тогда как в Java
и Python – как минимум в два раза больше. Еще одно преимущество
заключается в том, что при использования кодировки UTF-8 аппаратный порядок следования байтов не имеет значения, тогда как при
использовании кодировок UTF-16 и UTF-32 его необходимо учитывать (например, чтобы обеспечить корректное декодирование текста,
может потребоваться использовать кодировку UTF-16 с обратным
порядком следования байт). Кроме того, учитывая, что кодировка
UTF-8 фактически стала стандартом кодирования текстовых файлов во всем мире, в других языках программирования приходится
кодировать и декодировать такие файлы, чтобы обеспечить преобразование их содержимого во внутреннее представление Юникода и
обратно, тогда как в Go можно непосредственно читать и записывать
такие файлы. Помимо этого, некоторые крупные библиотеки (такие
как GTK+) уже используют строки символов в кодировке UTF-8,
поэтому программы на языке Go могут работать с ними, минуя этап
кодирования/декодирования.

Фактически строки в языке Go столь же удобны и просты в использовании, как и в других языках. Это станет очевидно, как только
вы познакомитесь с идиомами работы со строками в языке Go.

## 3.1. Литералы, операторы и экранированные последовательности

Строковые литералы определяются с помощью кавычек (" ) или обратных апострофов (`). Кавычки используются для определения интерпретируемых строковых литералов – такие строки поддерживают
экранированные последовательности , перечисленные в табл. 3.1 (ниже), но они не могут занимать несколько строк в программе. Обратные апострофы используются для определения обычных строковых
литералов, такие строки могут занимать несколько строк в программе,
но они не поддерживают экранированных последовательностей и могут содержать любые символы, кроме обратных апострофов. Интерпретируемые строковые литералы используются чаще, но для записи
многострочных сообщений, разметки HTML и регулярных выражений удобнее использовать строковые литералы в обратных апострофах. Ниже приводятся несколько примеров литералов.

{% highlight go %}  
text1 := "\"what’s that?\", he said" // Интерпретируемый строковый литерал
text2 := `"what’s that?", he said` // Простой строковый литерал
radicals := " \u221A \U0000221a" // radicals == "  "
{% endhighlight %}

-- Таблица 3.1. Экранированные последовательности

В этом примере были созданы три переменные типа string, при
этом переменные text1 и text2 содержат один и тот же текст. Поскольку для файлов с расширением .go используется кодировка
UTF-8, в них можно включать любые символы Юникода. Однако
сохраняется возможность использовать экранированные последовательности Юникода, как это сделано для второго и третьего символов . Здесь невозможно использовать 8-битное восьмеричное
или шестнадцатеричное представление кодового пункта, так как
они ограничены диапазоном от U+0000 до U+00FF, слишком узкого для представления кодового пункта U+221A, соответствующего
символу .

Если потребуется определить длинный и интерпретируемый
строковый литерал, разместив его на нескольких строках в тексте
программы, можно разбить его на несколько литералов и объединить их оператором конкатенации (+ ). Кроме того, несмотря на то
что строки в языке Go являются неизменяемыми , они поддерживают
оператор добавления += . Он замещает имеющуюся строку результатом конкатенации двух строк, если емкости исходной строки недостаточно для размещения добавляемой строки. Эти операторы перечислены в табл. 3.2 (ниже). Строки могут сравниваться с помощью
операторов сравнения (см. табл. 2.3 выше). Ниже демонстрируется
использование этих операторов:

{% highlight go %}  
book := "The Spirit Level" + " by Richard Wilkinson" // Конкатенация строк
book += " and Kate Pickett"							 // Добавление в конец строки
fmt.Println("Josey" < "Jos ï ", "Josey" == "Jos ï ") // Сравнение строк
{% endhighlight %}

В результате выполнения этого фрагмента переменная book будет содержать текст «The Spirit Level by Richard Wilkinson and Kate
Pickett», а в поток os.Stdout будет выведена строка «true false».

## 3.2. Сравнение строк

-- Таблица 3.2. Операции со строками

Как уже отмечалось, строки в языке Go поддерживают обычные
операторы сравнения (<, <=, ==, !=, >, >=), перечисленные в табл. 2.3
(выше). Сравнение строк этими операторами выполняется побайтно.
Строки могут сравниваться непосредственно, например на равенство,
и косвенно, например когда оператор < используется для сравнения
строк с целью сортировки содержимого среза []string. К сожалению,
при выполнении сравнения могут возникать три проблемы. 1
Эти проблемы проявляются во всех языках программирования,
поддерживающих строки Юникода, и не являются характерными
только для языка Go.

Первая проблема – в том, что некоторые символы Юникода могут
быть представлены двумя и более разными последовательностями
байт. Например, символ Å может обозначать единицу измерения расстояний «ангстрем» или быть простым символом A с кружочком над
ним – оба символа часто не различимы на глаз. Символу «ангстрем» в
Юникоде соответствует кодовый пункт U+212B, а символу A с кружочком над ним – кодовый пункт U+00C5 или два кодовых пункта U+0041
(A) и U+030A (° – дополнительный кружок сверху). В кодировке UTF-8
символ «ангстрем» ( Å ) представляет последовательность байтов [0xE2,
0x84, 0xAB], символ Å – последовательность [0xC3, 0x85], а символ A с
дополнительным символом ° – последовательность [0x41, 0xCC, 0x81].
Разумеется, с точки зрения пользователя, оба символа Ë ничем не отличаются и при сравнении должны определяться как одинаковые, независимо от того, какими последовательностями байтов они представлены.

Первая проблема не столь существенна, как может показаться,
потому что для всех последовательностей байт (то есть строк) в кодировке UTF-8 в языке Go воспроизводятся одни и те же кодовые
пункты. Это означает, например, что символ é в языке Go, в символьных или в строковых литералах, всегда будет представлен одной и той же последовательностью байтов. И конечно же при работе
с текстом, состоящим исключительно из символов ASCII (то есть
на английском языке), эта проблема вообще никак не проявляется.
И даже при работе с текстом, содержащим не-ASCII символы, проблема возникает, только когда существуют два разных символа, имеющих одинаковое начертание, или когда байты UTF-8 поступают в
программу из внешних источников, использующих допустимые, но
другие отображения кодовых пунктов в последовательности байтов.
Если это обстоятельство превращается в действительно серьезную
проблему, всегда можно написать собственную функцию нормализации , гарантирующую, например, что символ é всегда будет представлен последовательностью байтов [0xC3, 0xA9] (используемой
в языке Go по умолчанию), а не, к примеру, последовательностью
[0x65, 0xCC, 0x81] (то есть комбинацией символов e и  ́ ). Принципы
нормализации символов Юникода подробно разъясняются в документе «Unicode Normalization Forms» (формы нормализации Юникода) (unicode.org/reports/tr15). На момент написания этих строк в
состав стандартной библиотеки языка Go входил экспериментальный пакет, реализующий нормализацию (exp/norm).

Поскольку первая проблема в действительности проявляется,
только когда дело доходит до обработки строк, поступающих из
внешних источников, и только если используется иной принцип
отображения кодовых пунктов в последовательности байтов, отличный от принятого в языке Go, лучшим ее решением будет изоляция программного кода, принимающего внешние данные. При таком подходе изолированный код мог бы выполнять нормализацию
принимаемых строк до того, как они попадут в программу.

Вторая проблема в том, что бывают ситуации, когда пользователи
могут вполне обоснованно ожидать, что разные символы должны
определяться как равные. Например, пользуясь программой, осуществляющей поиск по тексту , пользователь может ввести слово
«file». Естественно, он надеется, что программа отыщет все вхождения слова «file», а также все вхождения «fi-le» (то есть слог «fi» в
конце одной строки, за которым следует слог «le» в начале следующей). Аналогично он может надеяться отыскать по строке поиска
«5» все вхождения «5», « 5 », « 5 » и даже «g». Как и первая, эта проблема решается с помощью нормализации некоторого вида.

Третья проблема состоит в том, что порядок сортировки некоторых
символов зависит от языка, на котором набран текст. Например, в
шведском алфавите символ ä следует за символом z, тогда как в телефонных справочниках на немецком языке символ ä при сортировке
соответствует паре символов ae, а в словарях немецкого языка он соответствует символу a. Еще один пример: в английском языке символ
ø при сортировке соответствует символу o, а в датском и норвежском
языках он должен следовать за символом z. Существует не только
огромное количество правил, подобных упомянутым, но они еще осложняются тем обстоятельством, что иногда одно и то же приложение
могут использовать люди разных национальностей (ожидающие получить разный порядок сортировки). Кроме того, иногда строки могут содержать слова на разных языках (например, несколько слов на
испанском и несколько слов на английском), а к некоторым символам
(таким как стрелки, типографские знаки и математические символы)
вообще неприменимо понятие порядка следования.

Но большим плюсом является то, что в языке Go строки сравниваются побайтно, в соответствии с порядком сортировки символов
ASCII. И при сравнении строк, состоящих только из символов нижнего или верхнего регистра, будет получаться порядок сортировки,
более естественный для английского языка, как будет показано в
примере ниже (§4.2.4).

## 3.3. Символы и строки

Символы в языке Go могут быть представлены двумя разными
(но взаимозаменяемыми) способами. Единственный символ может
быть представлен значением типа rune (или int32 ). С этого момента
термины «символ», «кодовый пункт», «символ Юникода» и «кодовый пункт Юникода» будут использоваться взаимозаменяемо для
ссылки на значение типа rune (или int32), хранящее единственный
символ. Строки в языке Go представлены последовательностями из
нуля или более символов – каждый символ внутри строки представлен одним или более байт в кодировке UTF-8.

С помощью операции преобразования типа (string(символ)) единственный символ можно преобразовать в односимвольную строку.
Например:

{% highlight go %}  
ìs := ""
for _, char := range []rune{‘ ì ’, 0xE6, 0346, 230, ‘\xE6’, ‘\u00E6’} {
	fmt.Printf("[0x%X ‘%c’] ", char, char)
	ìs += string(char)
}
{% endhighlight %}

Этот фрагмент выведет строку, в которой текст [0xE6 ‘ ì ’] повторяется шесть раз, а после его выполнения переменная ì s будет
содержать строку, содержащую текст ìììììì . (Более эффективные альтернативы оператору += для использования в цикле будут
показаны чуть ниже.)

Преобразовать строку в срез со значениями типа rune (то есть кодовых пунктов) можно с помощью операции преобразования chars
:= []rune(s), где s – значение типа string. Значение chars в этом
случае будет иметь тип []int32, поскольку тип rune является синонимом типа int32. Такая возможность может пригодиться, например,
когда потребуется выполнить посимвольный анализ строки и при
этом выбирать символы, стоящие перед и после текущего. Обратное
преобразование выполняется так же просто: s := string(chars), где
значение chars имеет тип []rune, или []int32, а значение s будет
иметь тип string. Оба преобразования имеют определенные накладные расходы, но выполняются достаточно быстро (имеют сложность
O(n), где n – количество байт; см. врезку «Нотация O(...)» ниже).
Дополнительные операции преобразования строк перечислены в
табл. 3.2 (выше), а преобразования «числоlстрока» – в табл. 3.8
и табл. 3.9 (ниже).

Несмотря на удобство, оператор += обеспечивает не самый эффективный способ наращивания строк в циклах. Более удачный способ
(хорошо знакомый программистам на Python) заключается в заполнении среза со строками ([]string) с последующим объединением
его элементов вызовом функции strings.Join(). Однако в языке Go
существует еще более эффективный путь , напоминающий использование класса StringBuilder в языке Java. Например:

{% highlight go %}  
var buffer bytes.Buffer
for {
	if piece, ok := getNextValidString(); ok {
		buffer.WriteString(piece)
	} else {
		break
	}
}
fmt.Print(buffer.String(), "\n")
{% endhighlight %}

Фрагмент начинается с создания пустого значения типа bytes.
Buffer . Затем выполняется запись каждой строки в буфер с помощью его метода bytes.Buffer.WriteString() . (При необходимости
можно было бы также организовать запись строки-разделителя между фрагментами.) В конце вызывается метод bytes.Buffer.String() ,
извлекающий окончательную строку. (Особенности использования
мощного и гибкого типа bytes.Buffer будут показаны ниже.)

Прием накопления строки в bytes.Buffer потенциально более эффективен с точки зрения вычислительных ресурсов и потребляемой
памяти, чем прием на основе оператора +=, особенно при большом
количестве объединяемых строк.

Цикл for ...range (§5.3) с успехом можно использовать для
итераций по символам строки. В этом случае в каждой итерации
программе становятся доступны индекс текущей позиции в строке
и кодовый пункт в этой позиции. Ниже приводятся пример использования этой версии цикла и вывод, полученный в результате выполнения данного фрагмента.

{% highlight go %}  
phrase := "v ë tt og t þ rt"
fmt.Printf("string: \"%s\"\n", phrase)
fmt.Println("index rune char bytes")
for index, char := range phrase {
	fmt.Printf("%-2d %U ‘%c’ % X\n", index, char, char,	[]byte(string(char)))
}
_______________
string: "v ë ttog t þ rt"
index rune	char 	bytes
0	U+0076	‘v’ 	76
1	U+00E5	‘ ë ’ 	C3 A5
3	U+0074	‘t’ 	74
4	U+0074	‘t’ 	74
5	U+0020	‘ ‘		20
6	U+006F	‘o’		6F
7	U+0067	‘g’		67
8	U+0020	‘ ‘		20
9	U+0074	‘t’		74
10	U+00F8	‘ þ ’	C3 B8
12	U+0072	‘r’		72
13	U+0074	‘t’		74
{% endhighlight %}

<pre>
Нотация O(...)
Нотация O(...) используется в теории сложности алгоритмов для
описания эффективности и потребления памяти конкретными алгоритмами. В большинстве случаев в скобках указываются значения в
пропорциях к n – числу обрабатываемых элементов или длине обрабатываемого элемента. В скобках также может указываться мера
потребления памяти или время обработки.
Запись O(1) означает постоянное время, то есть время обработки не
зависит от величины n. Запись O(log n) означает увеличение времени
по логарифмическому закону – это очень быстрый алгоритм, время
работы которого пропорционально log n. Запись O(n) означает линейное увеличение времени – это довольно быстрый алгоритм, время работы которого пропорционально n. Запись O(n 2 ) означает увеличение
времени по квадратичному закону – это медленный алгоритм, время
работы которого пропорционально n 2 . Запись O(n m ) означает увеличение времени по полиномиальному закону – скорость работы такого
алгоритма падает очень быстро с ростом n, особенно при значениях
m t 3. Запись O(n!) означает увеличение времени по факториальному
закону – даже при маленьких значениях n такой алгоритм становится
слишком медленным, чтобы иметь практическую ценность.
В этой книге обозначение O(...) используется в разных местах, чтобы
дать некоторое представление о стоимости тех или иных операций,
например преобразования значения типа string в значение типа []
rune .
</pre>

В начале фрагмента создается строковый литерал phrase и в
следующей строке выводится на экран. Затем выполняются итерации по символам в строке – в языке Go цикл for ...range автоматически декодирует байты UTF-8 в кодовые пункты Юникода
(значения типа rune), поэтому нет необходимости беспокоиться о
внутреннем их представлении. Для каждого символа выводится
номер его позиции, значение кодового пункта (в форме записи,
принятой в стандарте Юникода), сам символ и соответствующие
ему байты в кодировке UTF-8.

Чтобы получить список байтов, кодовые пункты (значения char
типа rune) преобразуются в строку (содержащую единственный символ, который состоит из одного или более байтов в кодировке UTF-8).
Затем эта односимвольная строка преобразуется в значение типа []
byte, то есть в срез с байтами, благодаря чему появляется возможность доступа к фактическим байтам. Преобразование []byte(string)
выполняется очень быстро (O(1)), так как []byte просто ссылается на
внутреннее представление строки string, без необходимости копировать какие-либо данные. То же справедливо и для обратного преобразования string([]byte) – здесь байты внутреннего представления
строки также никуда не копируются, поэтому данное преобразование
тоже имеет сложность O(1). Преобразования между строками и последовательностями байтов перечислены в табл. 3.2 (выше).

Спецификаторы формата %-2d, %U, %c и % X описываются ниже
(§3.5). Как будет показано далее, спецификатор %X используется для
вывода целых чисел в шестнадцатеричном виде, а когда он применяется к значению []byte, выводится последовательность чисел, состоящих из двух шестнадцатеричных цифр, по одному на каждый
байт. Наличие пробела в спецификаторе указывает, что байты должны выводиться через пробел.

На практике циклы for ...range, используемые для итераций по
символам строк, наряду с функциями из пакетов strings и fmt (и в
меньшей степени из пакетов strconv, unicode и unicode/utf8) обеспечивают все, что необходимо для обработки строк. Однако, помимо
этого, тип string поддерживает возможность создания срезов (поскольку во внутреннем представлении строка фактически является
значением типа []byte), что может оказаться весьма полезным, так
как исключает вероятность разрыва многобайтных символов пополам при обработке!

## 3.4. Индексирование и получение срезов строк

Как видно из табл. 3.2 (выше), язык Go поддерживает операцию получения срезов строк, используя синтаксис, напоминающий синтаксис
языка Python. Этот синтаксис можно использовать для получения
срезов значений любых типов, как будет показано в главе 4.

Поскольку строки в языке Go хранят текст в виде байтов в кодировке UTF-8, необходимо соблюдать меры предосторожности,
чтобы при создании срезов не нарушить границ символов. В этом
нет ничего сложного при работе с текстом, состоящим из 7-битных
символов ASCII, поскольку каждый символ представлен единственным байтом, но в других случаях ситуация может оказаться намного
более сложной, так как символы могут быть представлены одним и
более байтами. Как правило, в обычной практике вообще не требуется извлекать срезы строк – достаточно иметь простую возможность
итераций по символам в цикле for ...range, но иногда действительно бывает необходимо получить срез, чтобы извлечь подстроку. Один из способов, гарантирующих целостность границ символов
при извлечении среза, заключается в использовании функций из
пакета strings , таких как strings.Index() или strings.LastIndex().
Функции, входящие в пакет strings, перечислены в табл. 3.6 и
табл. 3.7 (ниже).

Для начала рассмотрим различные способы представления строки. Отсчет индексов, то есть позиций байтов UTF-8 в строке, начинается с 0 и продолжается до значения, определяющего длину
строки минус единицу. Также имеется возможность индексирования в обратном направлении – с конца строки, с использованием
индексов со значениями len(s) - n, где n – количество байтов,
отсчитываемых с конца. Например, для выражения s := "na õ ve",
на рис. 3.1 показана строка s в виде последовательностей символов
Юникода, кодовых пунктов и байтов, а также приводятся несколько
допустимых индексов и пара срезов.

Для доступа к каждой позиции в строке, изображенной на
рис. 3.1, можно использовать оператор индексирования [] , который
возвратит соответствующий ASCII-символ (как значение типа byte).
Например, s[0] == ‘n’, а s[len(s) - 1] == ‘e’. Первый байт последовательности, соответствующей символу ï , имеет индекс 2, но,
если обратиться к элементу строки s[2], программа получит только
первый байт (0xC3) символа ï в кодировке UTF-8 – подобное редко
требуется в программах.

!["Рис. 3.1. Строение строки"](/images/ris-3-1.jpg "Рис. 3.1. Строение строки")

Для строк, содержащих только 7-битные ASCII-символы, первый символ (в виде значения типа byte) можно извлечь с помощью выражения s[0], а последний – с помощью выражения
s[len(s) - 1]. Однако в общем случае для извлечения первого
символа (в виде значения типа rune, содержащего все байты UTF8, представляющие символ) следует использовать функцию utf8.
DecodeRuneInString() , а для извлечения последнего символа – функцию utf8.DecodeLastRuneInString() (см. табл. 3.10 ниже).

Для доступа к отдельным символам имеется несколько возможностей. Для строк, содержащих только 7-битные ASCII-символы,
можно использовать обычный оператор индексирования [], обеспечивающий очень быстрый (O(1)) доступ. В случае с другими
строками можно преобразовать строку в значение типа []rune и использовать оператор индексирования [] с этим значением. В этом
случае индексирование тоже выполняется очень быстро (O(1)), но
сама операция преобразования является достаточно дорогостоящей,
с точки зрения производительности и потребления памяти (O(n)).

В случае с примером, представленным выше, если записать инструкцию chars := []rune(s), будет создана переменная chars, хранящая срез значений типа rune (то есть int32) с пятью кодовыми
пунктами, представляющими шесть байт, как показано на рис. 3.1.
Напомню, что любое значение типа rune (кодовый пункт) легко
можно преобразовать обратно в строку, содержащую единственный
символ, с помощью выражения преобразования string(char).

Для произвольных строк (то есть для строк, которые могут содержать неASCII-символы), обычная операция индексирования далеко
не всегда дает желаемый результат. Вместо нее следует использовать
операцию получения среза строки, который также позволяет получить
строку вместо байтов. Для большей надежности извлечения срезов из
произвольных строк, определения позиции символа, начиная с которого или заканчивая которым требуется получить срез, лучше использовать функции из пакета strings – см. табл. 3.6 и табл. 3.7 (ниже).
Следующее равенство справедливо не только для срезов строк, но
и для срезов любых других типов:

{% highlight go %}
s == s[:i] + s[i:] // s – это строка; i – значение типа int; 0 <= i <= len(s)
{% endhighlight %}

Теперь рассмотрим пример извлечения среза с использованием
упрощенного подхода. Допустим, что имеется строка, из которой
требуется извлечь первое и последнее слово. Ниже представлен простейший способ решения этой задачи:


{% highlight go %}
line := "r þ de og gule sl þ jfer"
i := strings.Index(line, " ")		// Получить индекс первого пробела
firstWord := line[:i]				// Получить срез до первого пробела
j := strings.LastIndex(line, " ")	// Получить индекс последнего пробела
lastWord := line[j+1:]				// Получить срез от последнего пробела
fmt.Println(firstWord, lastWord)	// Выведет:	r þ de sl þ jfer
{% endhighlight %}

Переменной firstWord (типа string) будут присвоены байты из
строки line, начиная с позиции 0 (первый байт) до позиции с индексом i - 1 (то есть до последнего байта перед пробелом включительно), потому что срезы извлекаются до конечной, указанной
позиции, не включая ее. Аналогично переменной lastWord будут
присвоены байты из строки line, начиная с позиции j + 1 (первый
байт после пробела), до последнего байта в строке line включительно (то есть до позиции с индексом len(line) - 1).

Этот способ прекрасно подходит для случая с пробелами и другими 7-битными ASCII-символами, но он не пригоден для случаев,
когда слова отделяются произвольными пробельными символами
Юникода , такими как U+2028 (Line Separator, L/S – разделитель строк)
или U+2029 (Paragraph Separator, P/S – разделитель абзацев).

Ниже показан пример поиска первого и последнего слова в строках,
где слова могут разделяться произвольными пробельными символами.


{% highlight go %}
line := "r ë t þ rt\u2028v ì r"
i := strings.IndexFunc(line, unicode.IsSpace)		// i == 3
firstWord := line[:i]
j := strings.LastIndexFunc(line, unicode.IsSpace)	// j == 9
_, size := utf8.DecodeRuneInString(line[j:])		// size == 3
lastWord := line[j+size:]							// j + size == 12
fmt.Println(firstWord, lastWord)					// Выведет: r ë v ì r
{% endhighlight %}

Содержимое строки line в виде последовательности символов, кодовых пунктов и байтов показано на рис. 3.2. Здесь также показаны
номера позиций байтов и срезы, получаемые во фрагменте кода выше.


!["Рис. 3.2. Строение строки с пробельными символами"](/images/ris-3-2.jpg "Рис. 3.2. Строение строки с пробельными символами")


Функция strings.IndexFunc() возвращает индекс первой позиции
в строке, определяемой первым аргументом, для которой функция,
определяемая вторым аргументом (имеющая сигнатуру func(rune)
bool), вернет true. Функция strings.LastIndexFunc() действует аналогично, за исключением того, что она начинает просмотр строки с
конца и возвращает индекс последней позиции, для которой функция во втором аргументе вернет true. Здесь во втором аргументе
передается функция IsSpace() из пакета unicode – она принимает
кодовый пункт Юникода (типа rune) в виде единственного аргумента и возвращает true, если он соответствует пробельному символу
(см. табл. 3.11 ниже). Имена функций интерпретируются как ссылки
на функции , поэтому они могут передаваться в виде параметров другим функциям, при условии что сигнатуры передаваемых функций
соответствуют типам параметров (§4.1).

Операции поиска первого пробельного символа с помощью
функции strings.IndexFunc() и извлечения среза от начала строки до этого символа (не включая его), чтобы получить первое
слово, реализуются просто. Но при поиске последнего пробельного символа необходимо быть внимательными, потому что некоторые пробельные символы в кодировке UTF-8 кодируются
более чем одним байтом. В данном примере эта проблема решена
за счет использования функции utf8.DecodeRuneInString(), возвращающей количество байт в первом символе среза строки, начинающегося с последнего пробельного символа. Затем это число
добавляется к индексу последнего пробельного символа, чтобы
перешагнуть через него, то есть через байты, представляющие
этот пробельный символ, и извлекается срез, содержащий только
последнее слово.